{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "premium"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Melanoma detection in dermatoscopic images using contextual information and Convolutional Neural Networks.\n",
        "By Brenda Farinha Fernandes\n",
        "\n",
        "November 2022"
      ],
      "metadata": {
        "id": "UAioD90XhM__"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup"
      ],
      "metadata": {
        "id": "jsDdSko0DGUu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Required libraries"
      ],
      "metadata": {
        "id": "xx72Q9IADH1l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "import zipfile\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.model_selection import train_test_split \n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "import tensorflow as tf"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vz8FpjDZDJlH",
        "outputId": "acea887a-7d25-45b0-9e0d-bc4b4db271e1"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "GPU Information"
      ],
      "metadata": {
        "id": "q1y4cYxo-kLN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Not connected to a GPU')\n",
        "else:\n",
        "  print(gpu_info)\n",
        "  print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n",
        "\n",
        "strategy = tf.distribute.get_strategy()\n",
        "REPLICAS = strategy.num_replicas_in_sync\n",
        "print('Number of replicas:', REPLICAS)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hsz0NJ1C-nHR",
        "outputId": "8ea05fa2-9b50-4e49-aa66-b020c52e89f2"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sun Feb 26 12:11:24 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 525.85.12    Driver Version: 525.85.12    CUDA Version: 12.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  NVIDIA A100-SXM...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   35C    P0    48W / 400W |      0MiB / 40960MiB |      0%      Default |\n",
            "|                               |                      |             Disabled |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n",
            "Num GPUs Available:  1\n",
            "Number of replicas: 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "RAM Information"
      ],
      "metadata": {
        "id": "be7OX1vn-6HD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from psutil import virtual_memory\n",
        "ram_gb = virtual_memory().total / 1e9\n",
        "print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n",
        "\n",
        "if ram_gb < 20:\n",
        "  print('Not using a high-RAM runtime')\n",
        "else:\n",
        "  print('You are using a high-RAM runtime!')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N1iGHAAb-3Pi",
        "outputId": "42b60cd0-748e-44da-e9ea-0903c603c873"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Your runtime has 89.6 gigabytes of available RAM\n",
            "\n",
            "You are using a high-RAM runtime!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Global variables"
      ],
      "metadata": {
        "id": "m--m_NGiFlNl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "PATH_dataset_images_zip = '/content/drive/MyDrive/PFG_MELANOMA/ISIC_2020_Training_JPEG.zip'\n",
        "PATH_dataset_images = '/content/drive/MyDrive/PFG_MELANOMA/images'\n",
        "PATH_dataset_csv = '/content/drive/MyDrive/PFG_MELANOMA/ISIC_2020_Training_GroundTruth.csv'"
      ],
      "metadata": {
        "id": "evelS1nqFm3a"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "IMG_HEIGHT = 124\n",
        "IMG_WIDTH = 124"
      ],
      "metadata": {
        "id": "nq1dFg8WQnwt"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
        "BATCH_SIZE = 64"
      ],
      "metadata": {
        "id": "MipXk6x2HwSu"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data preproccesing"
      ],
      "metadata": {
        "id": "7Fd-xHZVDMaH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Read [SIIM-ISIC 2020 Melanoma Classification Challenge Dataset](https://doi.org/10.34970/2020-ds01) "
      ],
      "metadata": {
        "id": "5c0DD27QFKLl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def read_dataset(dataset_unzip = False): \n",
        "\n",
        "  # Unzip images from \"/content/drive/MyDrive/PFG_MELANOMA/ISIC_2020_Training_JPEG.zip\"\n",
        "  if dataset_unzip: \n",
        "    zipfile.ZipFile(PATH_dataset_images_zip).extractall(PATH_dataset_images)\n",
        "  \n",
        "  df = pd.DataFrame(pd.read_csv(f'{PATH_dataset_csv}'))\n",
        "\n",
        "  train_df, val_df = train_test_split(df, random_state=42, shuffle=True, stratify=df['target'])\n",
        "\n",
        "  return train_df, val_df"
      ],
      "metadata": {
        "id": "Co9nC28YDVV5"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def decode_image(image_path, label):\n",
        "\n",
        "  image = tf.io.read_file(image_path)\n",
        "  image = tf.image.decode_jpeg(image, channels=3)\n",
        "  image = tf.image.resize(image, [IMG_HEIGHT, IMG_WIDTH])\n",
        "  image = tf.cast(image, tf.float32) / 255.0\n",
        "\n",
        "  return image, label"
      ],
      "metadata": {
        "id": "QN4nf-BZHVyz"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def image_augmentation(image, label): \n",
        "\n",
        "  image = tf.image.random_flip_left_right(image)\n",
        "  image = tf.image.random_flip_up_down(image)\n",
        "  image = tf.image.random_hue(image, 0.025)\n",
        "  image = tf.image.random_saturation(image, 0.6, 1.4)\n",
        "  image = tf.image.random_contrast(image, 0.7, 1.4)\n",
        "  image = tf.image.random_brightness(image, 0.1)\n",
        "\n",
        "  return image, label"
      ],
      "metadata": {
        "id": "PfVvDW8V1zO7"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load dataset: \n",
        "* `map()`: This transformation applies map_func to each element of this dataset, and returns a new dataset containing the transformed elements\n",
        "\n",
        "* `repeat()`: Repeats this dataset so each original value is seen count times.\n",
        "\n",
        "* `shuffle()`: Randomly shuffles the elements of this dataset.\n",
        "\n",
        "* `batch()`: Combines consecutive elements of this dataset into batches.\n",
        "\n",
        "* `prefetch()` : Most dataset input pipelines should end with a call to prefetch. This allows later elements to be prepared while the current element is being processed. prefetch( ) doesnâ€™t allow CPU stand idle. When model is training prefetch continue prepare data while GPU is busy.\n",
        "\n",
        "* `cache()` : The first time the dataset is iterated over, its elements will be cached either in the specified file or in memory. Subsequent iterations will use the cached data. When caching to a file, the cached data will persist across runs. Even the first iteration through the data will read from the cache file.\n",
        "\n"
      ],
      "metadata": {
        "id": "EBaLtJhoGiry"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_dataset(df, deterministic = False, augment = False, cache = False): \n",
        "\n",
        "  labels = df[\"target\"].values\n",
        "  images = f'{PATH_dataset_images}/' + df[\"image_name\"].values +\".jpg\"\n",
        "  \n",
        "  ds = tf.data.Dataset.from_tensor_slices((images, labels))\n",
        "\n",
        "  if not deterministic:\n",
        "    options = tf.data.Options()\n",
        "    options.experimental_deterministic = False\n",
        "    ds = ds.with_options(options)\n",
        "\n",
        "  ds = ds.map(decode_image, num_parallel_calls=AUTOTUNE)\n",
        "\n",
        "  if augment: \n",
        "    ds = ds.map(image_augmentation, num_parallel_calls=AUTOTUNE)\n",
        "    ds = ds.repeat()\n",
        "    ds.shuffle(buffer_size = 2048)\n",
        "  \n",
        "  ds = ds.batch(BATCH_SIZE)\n",
        "\n",
        "  if cache:\n",
        "    ds = ds.cache()\n",
        "\n",
        "  ds = ds.prefetch(AUTOTUNE)\n",
        "\n",
        "  return ds"
      ],
      "metadata": {
        "id": "PyU5x5mzGlSQ"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Show images"
      ],
      "metadata": {
        "id": "S4LyLsUCWppO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def show_images(ds):\n",
        "\n",
        "  row, col = 3,5\n",
        "  fig = plt.figure(figsize=(2*col, 2*row))\n",
        "  for _row in range(row):\n",
        "    for _col in range(col):\n",
        "      plt.subplot(row, col, _row*col + _col +1)\n",
        "      for images, labels in ds.take(1):\n",
        "        img = images[0].numpy()\n",
        "        plt.imshow(img)\n",
        "        plt.title(labels[0].numpy())\n",
        "        plt.axis(False)\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "ICQM1Bl9Wrtz"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model"
      ],
      "metadata": {
        "id": "1KPxcGnYGUSe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_df, val_df = read_dataset(dataset_unzip = False)"
      ],
      "metadata": {
        "id": "MuncGR37GYPv"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Distribution dataset"
      ],
      "metadata": {
        "id": "R2k_06A5VOFL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_total = len(train_df)\n",
        "train_malignant = len(train_df[train_df[\"target\"] == 1])\n",
        "train_benign = len(train_df[train_df[\"target\"] == 0])\n",
        "\n",
        "val_total = len(val_df)\n",
        "val_malignant = len(val_df[val_df[\"target\"] == 1])\n",
        "val_benign = len(val_df[val_df[\"target\"] == 0])\n",
        "\n",
        "print(\"Number of training files =\", train_total)\n",
        "print(\"\\tNumber of malignant training files =\", train_malignant)\n",
        "print(\"\\tNumber of benign training files =\", train_benign)\n",
        "\n",
        "print(\"\\nNumber of validation files =\", val_total)\n",
        "print(\"\\tNumber of malignant validation files =\", val_malignant)\n",
        "print(\"\\tNumber of benign validation files =\", val_benign)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oh2HcGvnVU3E",
        "outputId": "0c1c0526-c171-4fb1-d906-9ee0b2b9dd02"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of training files = 24843\n",
            "\tNumber of malignant training files = 437\n",
            "\tNumber of benign training files = 24406\n",
            "\n",
            "Number of validation files = 8282\n",
            "\tNumber of malignant validation files = 146\n",
            "\tNumber of benign validation files = 8136\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "STEPS_PER_EPOCH_TRAIN = train_total // BATCH_SIZE\n",
        "STEPS_PER_EPOCH_VAL = val_total // BATCH_SIZE\n",
        "\n",
        "EPOCHS = 15\n",
        "print(\"Number of steps per epoch in training:\", STEPS_PER_EPOCH_TRAIN)\n",
        "print(\"Number of steps per epoch in validation:\", STEPS_PER_EPOCH_VAL)"
      ],
      "metadata": {
        "id": "hHLpBkEVaM3U",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7d8f36dc-c205-4696-fb1d-83b95b78d9ab"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of steps per epoch in training: 388\n",
            "Number of steps per epoch in validation: 129\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds = load_dataset(train_df, deterministic = False, augment = True, cache = False)\n",
        "val_ds = load_dataset(val_df, deterministic = False, augment = False, cache = True)"
      ],
      "metadata": {
        "id": "ilOtoNErSGU4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Class weights in training dataset"
      ],
      "metadata": {
        "id": "YEA4VMOqXHV3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "weight_malignant = (train_total/train_malignant)/2.0\n",
        "weight_benign = (train_total/train_benign)/2.0\n",
        "\n",
        "class_weight = {0: weight_benign, 1: weight_malignant}\n",
        "\n",
        "print(\"Weight for benign cases = \", class_weight[0])\n",
        "print(\"Weight for malignant cases = \", class_weight[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "028X5dXuXMmq",
        "outputId": "fbaab163-1d2c-40a9-e2f5-0a382b5cbe97"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Weight for benign cases =  0.5089527165451119\n",
            "Weight for malignant cases =  28.424485125858123\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Defining Callbacks\n",
        "\n",
        "*   `EarlyStopping`: Stop training when a monitored metric has stopped improving.\n",
        "*   `ModelCheckpoint`: Callback to save the Keras model or model weights at some frequency.\n",
        "\n"
      ],
      "metadata": {
        "id": "4XB8Fgy8XTar"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "callback_early_stopping = tf.keras.callbacks.EarlyStopping(\n",
        "    patience = 15, \n",
        "    verbose = 0, \n",
        "    restore_best_weights = True)\n",
        "\n",
        "callbacks_lr_reduce = tf.keras.callbacks.ReduceLROnPlateau(\n",
        "    monitor = \"val_auc\", \n",
        "    factor = 0.1, \n",
        "    patience = 10,\n",
        "    verbose = 0, \n",
        "    min_lr = 1e-6)\n",
        "\n",
        "callback_checkpoint = tf.keras.callbacks.ModelCheckpoint(\n",
        "    \"melanoma_detection_weights.h5\",\n",
        "    save_weights_only=True,\n",
        "    monitor='val_auc',\n",
        "    mode='max',\n",
        "    save_best_only=True)"
      ],
      "metadata": {
        "id": "vDxAnjifXVkh"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with strategy.scope():\n",
        "\n",
        "  input = tf.keras.layers.Input(shape=(IMG_HEIGHT, IMG_WIDTH, 3))\n",
        "  dummy = tf.keras.layers.Lambda(lambda x:x)(input)\n",
        "\n",
        "  encoder = tf.keras.applications.EfficientNetB6(\n",
        "      input_shape = (IMG_HEIGHT, IMG_WIDTH, 3),\n",
        "      include_top = False,\n",
        "      weights = 'imagenet'\n",
        "  )(dummy)\n",
        "  encoder.trainable = False\n",
        "\n",
        "  x = tf.keras.layers.GlobalAveragePooling2D()(encoder)\n",
        "  outputs = tf.keras.layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "\n",
        "  model = tf.keras.Model(input, outputs, name='aNetwork')\n",
        "  model.summary()\n",
        "\n",
        "  model.compile(\n",
        "      optimizer = tf.keras.optimizers.Adam(learning_rate=1e-3),\n",
        "      loss = tf.keras.losses.BinaryCrossentropy(label_smoothing = 0.05),\n",
        "      metrics = [tf.keras.metrics.AUC(name='auc')]\n",
        "  )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Pux74kaJj9U",
        "outputId": "8f05f0b1-d04d-45da-e4c3-1b147497f079"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"aNetwork\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 124, 124, 3)]     0         \n",
            "                                                                 \n",
            " lambda (Lambda)             (None, 124, 124, 3)       0         \n",
            "                                                                 \n",
            " efficientnetb6 (Functional)  (None, 4, 4, 2304)       40960143  \n",
            "                                                                 \n",
            " global_average_pooling2d (G  (None, 2304)             0         \n",
            " lobalAveragePooling2D)                                          \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1)                 2305      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 40,962,448\n",
            "Trainable params: 40,738,009\n",
            "Non-trainable params: 224,439\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history_B6 = model.fit(\n",
        "    train_ds, \n",
        "    verbose=1, \n",
        "    steps_per_epoch=STEPS_PER_EPOCH_TRAIN, \n",
        "    validation_data = val_ds, validation_steps = STEPS_PER_EPOCH_VAL,\n",
        "    epochs = EPOCHS, \n",
        "    callbacks=[callback_early_stopping, callbacks_lr_reduce, callback_checkpoint],\n",
        "    class_weight = class_weight) "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K7IQWKwOIV7r",
        "outputId": "ffd64c65-1368-4779-fa61-3ad2f2864598"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "388/388 [==============================] - 317s 535ms/step - loss: 0.6477 - auc: 0.7232 - val_loss: 0.8439 - val_auc: 0.7611 - lr: 0.0010\n",
            "Epoch 2/15\n",
            "388/388 [==============================] - 204s 527ms/step - loss: 0.5810 - auc: 0.7833 - val_loss: 1.1211 - val_auc: 0.7157 - lr: 0.0010\n",
            "Epoch 3/15\n",
            "388/388 [==============================] - 214s 553ms/step - loss: 0.5258 - auc: 0.8318 - val_loss: 0.6775 - val_auc: 0.8325 - lr: 0.0010\n",
            "Epoch 4/15\n",
            "388/388 [==============================] - 230s 595ms/step - loss: 0.5043 - auc: 0.8478 - val_loss: 0.6339 - val_auc: 0.4135 - lr: 0.0010\n",
            "Epoch 5/15\n",
            "388/388 [==============================] - 214s 553ms/step - loss: 0.4947 - auc: 0.8536 - val_loss: 1.2062 - val_auc: 0.7465 - lr: 0.0010\n",
            "Epoch 6/15\n",
            "388/388 [==============================] - 225s 582ms/step - loss: 0.5253 - auc: 0.8312 - val_loss: 0.7873 - val_auc: 0.6260 - lr: 0.0010\n",
            "Epoch 7/15\n",
            "388/388 [==============================] - 247s 638ms/step - loss: 0.4977 - auc: 0.8520 - val_loss: 2.1466 - val_auc: 0.4917 - lr: 0.0010\n",
            "Epoch 8/15\n",
            "388/388 [==============================] - 229s 592ms/step - loss: 0.4812 - auc: 0.8675 - val_loss: 0.4188 - val_auc: 0.6590 - lr: 0.0010\n",
            "Epoch 9/15\n",
            "388/388 [==============================] - 184s 475ms/step - loss: 0.4552 - auc: 0.8833 - val_loss: 0.1974 - val_auc: 0.7247 - lr: 0.0010\n",
            "Epoch 10/15\n",
            "388/388 [==============================] - 183s 472ms/step - loss: 0.4534 - auc: 0.8834 - val_loss: 0.5451 - val_auc: 0.5322 - lr: 0.0010\n",
            "Epoch 11/15\n",
            "388/388 [==============================] - 236s 609ms/step - loss: 0.4458 - auc: 0.8878 - val_loss: 0.2680 - val_auc: 0.7719 - lr: 0.0010\n",
            "Epoch 12/15\n",
            "388/388 [==============================] - 184s 474ms/step - loss: 0.4621 - auc: 0.8802 - val_loss: 0.3301 - val_auc: 0.2882 - lr: 0.0010\n",
            "Epoch 13/15\n",
            "388/388 [==============================] - 228s 589ms/step - loss: 0.4373 - auc: 0.8955 - val_loss: 0.4804 - val_auc: 0.5402 - lr: 0.0010\n",
            "Epoch 14/15\n",
            "388/388 [==============================] - 229s 591ms/step - loss: 0.4216 - auc: 0.9041 - val_loss: 0.3769 - val_auc: 0.6147 - lr: 0.0010\n",
            "Epoch 15/15\n",
            "388/388 [==============================] - 229s 590ms/step - loss: 0.4158 - auc: 0.9066 - val_loss: 0.4361 - val_auc: 0.7924 - lr: 0.0010\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(val_ds)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K1mEM-nBrVy7",
        "outputId": "07aba47e-d66c-4282-dcd7-73ee14b3180a"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "130/130 [==============================] - 50s 386ms/step - loss: 0.4361 - auc: 0.7905\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.4360809326171875, 0.7904637455940247]"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    }
  ]
}